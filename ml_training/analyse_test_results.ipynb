{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae847cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae44f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = Path(r\"C:\\Users\\mvand\\Documents\\Master EE\\Year 4\\Thesis\\data\\test_output\")\n",
    "pca_dir = test_dir / \"PCA_analysis_1\"\n",
    "\n",
    "select_set = 'set1'      # 'set1' 'set2'\n",
    "select_type = 'grid'     # 'grid' 'single'\n",
    "\n",
    "\n",
    "def get_pca_files(search_dir, dataset, datatype, fmt = '*.csv'): \n",
    "    \n",
    "    files = [file for file in search_dir.glob(fmt) if not 'class' in file.stem and datatype in file.stem and dataset in file.stem] \n",
    "    \n",
    "    pca_set = [file for file in files if not 'noPCA' in file.stem]\n",
    "    pca_bench = [file for file in files if 'noPCA' in file.stem ]\n",
    "     \n",
    "    return pca_set, pca_bench "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d90d5952",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO\n",
    "## - add std bars to bar plots \n",
    "## - check confusion matrix value plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff149ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_bench = [file for file in pca_dir.glob(\"*.csv\") if 'benchmark' in file.stem][0]\n",
    "\n",
    "df_bench = pd.read_csv(fn_bench)\n",
    "df_bench['hit_rate'] = df_bench['hit_ratio']\n",
    "\n",
    "stat_cols = ['accuracy', 'precision', 'recall', 'f1', 'balanced_acc', 'hit_rate',\n",
    "            'TP', 'TN', 'FP', 'FN', 'n', 'N']\n",
    "\n",
    "df_bench.groupby(by='model')[stat_cols].mean()\n",
    "\n",
    "labels = ['60%', '70%', '80%', '90%', '95%', '99%' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ec915c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## base \n",
    "\n",
    "def display_performance(benchmark_0, benchmark_1, list_performance_fn, grouper = 'model',\n",
    "                        stat_cols=['accuracy', 'precision', 'recall', 'f1', 'balanced_acc'], performance_labels = [],\n",
    "                       out_dir = None, fn_stem = None):\n",
    "    \n",
    "    ## benchmark\n",
    "    sum_bench0 = benchmark_0.groupby(by=grouper)[stat_cols].mean()\n",
    "    bench0_algs = sum_bench0.index.values\n",
    "\n",
    "    ## benkchmark performance model\n",
    "    sum_bench1 = benchmark_1.groupby(by=grouper)[stat_cols].mean() \n",
    "    eval_algs = sum_bench1.index.values \n",
    "    \n",
    "    ## load list of df_performance \n",
    "    list_performance_df = []\n",
    "    for fn in list_performance_fn:\n",
    "\n",
    "        _df = pd.read_csv(fn)\n",
    "        \n",
    "        sum_df = _df.groupby(by=grouper)[stat_cols].mean()\n",
    "        list_performance_df.append(sum_df)\n",
    "\n",
    "\n",
    "    for col in stat_cols:\n",
    "\n",
    "        fig = plt.figure(figsize=(16,2))\n",
    "        x_plot = 0.\n",
    "\n",
    "        x_tick_loc = []\n",
    "        x_tick_label = []\n",
    "\n",
    "        plt.title(col)\n",
    "\n",
    "        for alg in bench0_algs:\n",
    "            plt.bar(x_plot, sum_bench0.loc[alg,col], width=3, color='grey')\n",
    "\n",
    "            x_tick_loc.append(x_plot)\n",
    "            x_tick_label.append(alg)\n",
    "\n",
    "            x_plot += 3.5\n",
    "\n",
    "        x_plot += 2\n",
    "\n",
    "        for alg in eval_algs:\n",
    "\n",
    "            plt.bar(x_plot, sum_bench1.loc[alg,col], width=3, color='darkcyan')\n",
    "\n",
    "#             if len(performance_labels) > 0:\n",
    "#                 plt.text(x_plot-0.1, 0.1, performance_labels[0], rotation = 90, color = 'black', size=8)\n",
    "\n",
    "            x_tick_loc.append( (x_plot+ 2*len(list_performance_df)) )\n",
    "            x_tick_label.append(alg)\n",
    "            x_plot += 3.5 \n",
    "\n",
    "            for i, df_alg in enumerate(list_performance_df):\n",
    "                plt.bar(x_plot, df_alg.loc[alg,col], width = 3, color='cadetblue')\n",
    "\n",
    "                if len(performance_labels) > 0:\n",
    "                    plt.text(x_plot-1, 0.1, performance_labels[i], color = 'black', size=8, rotation=90)\n",
    "\n",
    "                x_plot += 3.5\n",
    "\n",
    "            x_plot += 2 \n",
    "\n",
    "#         plt.ylim(0,1)\n",
    "        plt.xticks(x_tick_loc, x_tick_label, rotation = 40)\n",
    "        plt.grid()\n",
    "        plt.xlim(-2, x_plot-1)\n",
    "\n",
    "        if out_dir != None:\n",
    "            if fn_stem == None:\n",
    "                fn = out_dir / 'plot_{}.png'.format(col)\n",
    "            else:\n",
    "                fn = out_dir / 'plot_{}_{}.png'.format(fn_stem, col)\n",
    "            plt.savefig(fn)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e36a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "### set 1 - single pixel \n",
    "labels = ['60%', '70%', '80%', '90%', '95%', '99%' ]\n",
    "display_cols = ['accuracy', 'precision', 'recall', 'f1', 'balanced_acc', 'hit_rate', 'TP', 'TN', 'FP']\n",
    "fig_dir = test_dir \n",
    "\n",
    "\n",
    "pca_set, pca_bench = get_pca_files(pca_dir, 'set1', 'single', fmt = '*.csv')\n",
    "\n",
    "df_pca_bench = pd.read_csv(pca_bench[0])\n",
    "\n",
    "# display_performance( df_bench, df_pca_bench, pca_set, performance_labels = labels,\n",
    "#                    stat_cols = display_cols, \n",
    "#                     out_dir = fig_dir, fn_stem='set1_pixel'\n",
    "#                    )\n",
    "\n",
    "# df_pca_bench.groupby(by='model')[stat_cols].mean()\n",
    "\n",
    "# print(pca_set[3].stem)\n",
    "# df = pd.read_csv(pca_set[3])\n",
    "# df.groupby(by='model')[stat_cols].mean()\n",
    "\n",
    "# print(pca_set[2].stem)\n",
    "# df = pd.read_csv(pca_set[2])\n",
    "# df.groupby(by='model')[stat_cols].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9271fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "### set 2 - single pixel \n",
    "labels = ['60%', '70%', '80%', '90%', '95%', '99%' ]\n",
    "\n",
    "pca_set, pca_bench = get_pca_files(pca_dir, 'set2', 'single', fmt = '*.csv')\n",
    "\n",
    "df_pca_bench = pd.read_csv(pca_bench[0])\n",
    "\n",
    "# display_performance( df_bench, df_pca_bench, pca_set, performance_labels = labels,  \n",
    "#                     stat_cols = display_cols, \n",
    "#                     out_dir = fig_dir, fn_stem='set2_pixel' \n",
    "#                    )\n",
    "    \n",
    "\n",
    "# df_pca_bench.groupby(by='model')[stat_cols].mean()\n",
    "\n",
    "# print(pca_set[3].stem)\n",
    "# df = pd.read_csv(pca_set[3])\n",
    "# df.groupby(by='model')[stat_cols].mean()\n",
    "\n",
    "# print(pca_set[2].stem)\n",
    "# df = pd.read_csv(pca_set[2])\n",
    "# df.groupby(by='model')[stat_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f32f7857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alg_pf_grid_80PCA_set1_6_diff\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>balanced_acc</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>n</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF-2</th>\n",
       "      <td>0.988243</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.010335</td>\n",
       "      <td>0.010229</td>\n",
       "      <td>0.505167</td>\n",
       "      <td>0.010335</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8051.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.8</td>\n",
       "      <td>96.8</td>\n",
       "      <td>8148.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM-2</th>\n",
       "      <td>0.989716</td>\n",
       "      <td>0.559859</td>\n",
       "      <td>0.161089</td>\n",
       "      <td>0.123515</td>\n",
       "      <td>0.579837</td>\n",
       "      <td>0.142514</td>\n",
       "      <td>13.8</td>\n",
       "      <td>8051.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>72.4</td>\n",
       "      <td>96.8</td>\n",
       "      <td>8148.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k-nn-2</th>\n",
       "      <td>0.988194</td>\n",
       "      <td>0.366666</td>\n",
       "      <td>0.006296</td>\n",
       "      <td>0.006167</td>\n",
       "      <td>0.503036</td>\n",
       "      <td>0.006231</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8051.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>94.4</td>\n",
       "      <td>96.8</td>\n",
       "      <td>8148.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR-2</th>\n",
       "      <td>0.990255</td>\n",
       "      <td>0.493918</td>\n",
       "      <td>0.237437</td>\n",
       "      <td>0.158885</td>\n",
       "      <td>0.617490</td>\n",
       "      <td>0.191852</td>\n",
       "      <td>18.6</td>\n",
       "      <td>8050.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>59.6</td>\n",
       "      <td>96.8</td>\n",
       "      <td>8148.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision    recall        f1  balanced_acc  hit_rate    TP  \\\n",
       "model                                                                           \n",
       "RF-2    0.988243   0.999999  0.010335  0.010229      0.505167  0.010335   1.0   \n",
       "SVM-2   0.989716   0.559859  0.161089  0.123515      0.579837  0.142514  13.8   \n",
       "k-nn-2  0.988194   0.366666  0.006296  0.006167      0.503036  0.006231   0.6   \n",
       "LR-2    0.990255   0.493918  0.237437  0.158885      0.617490  0.191852  18.6   \n",
       "\n",
       "            TN    FP    FN     n       N  \n",
       "model                                     \n",
       "RF-2    8051.8   0.0  95.8  96.8  8148.6  \n",
       "SVM-2   8051.0  11.4  72.4  96.8  8148.6  \n",
       "k-nn-2  8051.8   1.8  94.4  96.8  8148.6  \n",
       "LR-2    8050.6  19.8  59.6  96.8  8148.6  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### set 1- grid\n",
    "\n",
    "pca_set, pca_bench = get_pca_files(pca_dir, 'set1', 'grid', fmt = '*.csv')\n",
    "\n",
    "df_pca_bench = pd.read_csv(pca_bench[0])\n",
    "\n",
    "# display_performance( df_bench, df_pca_bench, pca_set, performance_labels = labels,  \n",
    "#                     stat_cols = display_cols, \n",
    "#                     out_dir = fig_dir, fn_stem='set2_pixel' \n",
    "#                    )\n",
    "\n",
    "# df_pca_bench.groupby(by='model')[stat_cols].mean()\n",
    "\n",
    "ix=2\n",
    "print(pca_set[ix].stem)\n",
    "df = pd.read_csv(pca_set[ix])\n",
    "df.groupby(by='model')[stat_cols].mean().loc[['RF-2', 'SVM-2', 'k-nn-2', 'LR-2' ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "731e9120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alg_pf_grid_90PCA_set2_6_diff\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>balanced_acc</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>n</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF-2</th>\n",
       "      <td>0.988269</td>\n",
       "      <td>0.799999</td>\n",
       "      <td>0.009015</td>\n",
       "      <td>0.008914</td>\n",
       "      <td>0.504494</td>\n",
       "      <td>0.009015</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7395.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>87.6</td>\n",
       "      <td>88.6</td>\n",
       "      <td>7484.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM-2</th>\n",
       "      <td>0.989523</td>\n",
       "      <td>0.600140</td>\n",
       "      <td>0.134204</td>\n",
       "      <td>0.107769</td>\n",
       "      <td>0.566616</td>\n",
       "      <td>0.123785</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7395.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>71.2</td>\n",
       "      <td>88.6</td>\n",
       "      <td>7484.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k-nn-2</th>\n",
       "      <td>0.988216</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>0.502164</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.4</td>\n",
       "      <td>7395.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>86.2</td>\n",
       "      <td>88.6</td>\n",
       "      <td>7484.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR-2</th>\n",
       "      <td>0.990326</td>\n",
       "      <td>0.417648</td>\n",
       "      <td>0.293774</td>\n",
       "      <td>0.169385</td>\n",
       "      <td>0.645083</td>\n",
       "      <td>0.209793</td>\n",
       "      <td>18.6</td>\n",
       "      <td>7393.4</td>\n",
       "      <td>26.8</td>\n",
       "      <td>45.6</td>\n",
       "      <td>88.6</td>\n",
       "      <td>7484.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision    recall        f1  balanced_acc  hit_rate    TP  \\\n",
       "model                                                                           \n",
       "RF-2    0.988269   0.799999  0.009015  0.008914      0.504494  0.009015   0.8   \n",
       "SVM-2   0.989523   0.600140  0.134204  0.107769      0.566616  0.123785  11.0   \n",
       "k-nn-2  0.988216   0.166667  0.004598  0.004469      0.502164  0.004520   0.4   \n",
       "LR-2    0.990326   0.417648  0.293774  0.169385      0.645083  0.209793  18.6   \n",
       "\n",
       "            TN    FP    FN     n       N  \n",
       "model                                     \n",
       "RF-2    7395.8   0.2  87.6  88.6  7484.4  \n",
       "SVM-2   7395.0   7.2  71.2  88.6  7484.4  \n",
       "k-nn-2  7395.8   2.0  86.2  88.6  7484.4  \n",
       "LR-2    7393.4  26.8  45.6  88.6  7484.4  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### set 2- grid\n",
    "\n",
    "pca_set, pca_bench = get_pca_files(pca_dir, 'set2', 'grid', fmt = '*.csv')\n",
    "\n",
    "df_pca_bench = pd.read_csv(pca_bench[0])\n",
    "\n",
    "# display_performance( df_bench, df_pca_bench, pca_set, performance_labels = labels,  \n",
    "#                     stat_cols = display_cols, \n",
    "#                     out_dir = fig_dir, fn_stem='set2_pixel' \n",
    "#                    )\n",
    "\n",
    "# df_pca_bench.groupby(by='model')[stat_cols].mean().loc[['RF-2', 'SVM-2', 'k-nn-2', 'LR-2' ]]\n",
    "\n",
    "ix=3\n",
    "print(pca_set[ix].stem)\n",
    "df = pd.read_csv(pca_set[ix])\n",
    "df.groupby(by='model')[stat_cols].mean().loc[['RF-2', 'SVM-2', 'k-nn-2', 'LR-2' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb020c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0df4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c1f8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2518484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773743c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9619dfb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a31ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c9a45d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b7449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5615e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bec582",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load classification results - analyse p0 and p1 for TP and FP\n",
    "\n",
    "class_files = [file for file in pca_dir.glob('*.csv') if 'class' in file.stem]\n",
    "set1_class = [file for file in class_files if 'set-1' in file.stem]\n",
    "set2_class = [file for file in class_files if 'set-2' in file.stem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc481c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(df, range_col, target_col, model, title, save_dir = None,\n",
    "                  label_1 = 'TP', label_2 = 'FP', id_col = 'tag'):\n",
    "    \n",
    "    ## TP \n",
    "    ## if prediction in one of range_col \n",
    "    if 'TP' in label_1:\n",
    "        \n",
    "        ix_TP = []\n",
    "        \n",
    "        for ix in df[id_col].unique(): \n",
    "            nTP = df[ (df[id_col] ==  ix) & (df[range_col] == 1) ]\n",
    "            \n",
    "            predit\n",
    "            \n",
    "            if df[ (df[id_col] ==ix) & (df[hat_col]==1.) ].index in nTP.index.values:\n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "        ## TP \n",
    "        plot_1 = df[ (df[range_col] ==1) & (df[hat_col]==1) ]        \n",
    "    \n",
    "    if 'TP' in label_2:\n",
    "        ## TP if prediction in one of range_col \n",
    "        plot_2 = df[ (df[range_col] ==1) & (df[hat_col]==1) ] \n",
    "    \n",
    "    ## FP \n",
    "    ## if 0 in range col, but 1 for hat_col \n",
    "    if 'FP' in label_1:\n",
    "        plot_1 = df[ (df[range_col] ==0) & (df[hat_col]==1) ] \n",
    "    \n",
    "    if 'FP' in label_2:\n",
    "        plot_2 = df[ (df[range_col] ==0) & (df[hat_col]==1) ] \n",
    "    \n",
    "    ## TN \n",
    "    ## if 0 in range col and 0 for hat_col \n",
    "    if 'TN' in label_1:\n",
    "        plot_1 = df[ (df[range_col] ==0) & (df[hat_col]==0) ] \n",
    "    \n",
    "    if 'TN' in label_2:\n",
    "        plot_2 = df[ (df[range_col] ==0) & (df[hat_col]==0) ] \n",
    "    \n",
    "    ## FN \n",
    "    ## if 0 in range col and 0 for hat_col \n",
    "    if 'FN' in label_1:\n",
    "        plot_1 = df[ (df[range_col] ==1) & (df[hat_col]==0) ] \n",
    "    \n",
    "    if 'FN' in label_2:\n",
    "        plot_2 = df[ (df[range_col] ==1) & (df[hat_col]==0) ] \n",
    "\n",
    "        \n",
    "    ## plot\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.hist(plot_1[p1_col], color = 'b', label = label_1, bins = bin_edges )\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.hist(plot_2[p1_col], color = 'r', alpha=0.3, label = label_2, bins = bin_edges )\n",
    "    \n",
    "    ax1.tick_params(axis='y', labelcolor='b')\n",
    "    ax2.tick_params(axis='y', labelcolor='r')\n",
    "    \n",
    "    ax1.set_xlim(0,1.05)\n",
    "    ax1.set_xlabel('Class 1 probability')\n",
    "    ax1.set_ylabel('n {}'.format(label_1), color='b')\n",
    "    ax2.set_ylabel('n {}'.format(label_2), color='r')\n",
    "    \n",
    "    fig.legend()\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    if save_dir != None:\n",
    "        fn = save_dir / '{}_{}_{}.png'.format(title, label_1, label_2)\n",
    "        print('Save: ', fn.stem)\n",
    "        plt.savefig(fn)\n",
    "        return fn \n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfddd33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SET -1 - TN and FP \n",
    "range_col = 'range_target'\n",
    "target_col = 'target'\n",
    "\n",
    "model = 'RF-2'\n",
    "p0_col = '{}_p0'.format(model)\n",
    "p1_col = '{}_p1'.format(model)\n",
    "hat_col = '{}_target'.format(model)\n",
    "\n",
    "bin_edges = np.arange(0,1.01, 0.02)\n",
    "\n",
    "label_files = ['set_1_60PCA_{}'.format(model),\n",
    "              'set_1_70PCA_{}'.format(model),\n",
    "              'set_1_80PCA_{}'.format(model),\n",
    "              'set_1_90PCA_{}'.format(model),\n",
    "              'set_1_95PCA_{}'.format(model),\n",
    "              'set_1_99PCA_{}'.format(model),\n",
    "              'set_1_noPCA_{}'.format(model)]\n",
    "\n",
    "\n",
    "for n, fn in enumerate(set1_class):\n",
    "    \n",
    "    df = pd.read_csv(fn, index_col=0)\n",
    "    \n",
    "    plot_confusion(df, range_col, target_col, model, label_files[n], save_dir = None,\n",
    "                  label_1 = 'TP', label_2 = 'FP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58131d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f75486",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_files = ['set_2_60PCA',\n",
    "              'set_2_70PCA',\n",
    "              'set_2_80PCA',\n",
    "              'set_2_90PCA',\n",
    "              'set_2_95PCA',\n",
    "              'set_2_99PCA',\n",
    "              'set_2_noPCA',]\n",
    "\n",
    "\n",
    "for n, fn in enumerate(set2_class):\n",
    "    \n",
    "    df = pd.read_csv(fn, index_col=0)\n",
    "    \n",
    "    plot_confusion(df, range_col, target_col, model, label_files[n], save_dir = None,\n",
    "                  label_1 = 'TP', label_2 = 'FP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb7c838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
