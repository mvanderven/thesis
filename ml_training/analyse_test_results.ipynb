{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85a6ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib.gridspec as gridspec\n",
    "import xarray as xr\n",
    "from matplotlib.pyplot import cm \n",
    "\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b506dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = Path(r\"C:\\Users\\mvand\\Documents\\Master EE\\Year 4\\Thesis\\data\\test_output\")\n",
    "pca_dir = test_dir / \"PCA_analysis_4\"\n",
    "\n",
    "select_set = 'set1_1'      # 'set1' 'set2'\n",
    "select_type = 'single'     # 'grid' 'single'\n",
    "labels = ['60%', '70%', '80%', '90%', '95%', '99%' ]\n",
    "\n",
    "def get_pca_files(search_dir, dataset, datatype, fmt = '*.csv'): \n",
    "    \n",
    "    files = [file for file in search_dir.glob(fmt) if not 'class' in file.stem and datatype in file.stem and dataset in file.stem] \n",
    "    \n",
    "    pca_set = [file for file in files if not 'noPCA' in file.stem]\n",
    "    pca_bench = [file for file in files if 'noPCA' in file.stem ]\n",
    "     \n",
    "    return pca_set, pca_bench "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2239862",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO\n",
    "## - add std bars to bar plots \n",
    "## - check confusion matrix value plots \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce3f2773",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir  = Path(r\"C:\\Users\\mvand\\Documents\\Master EE\\Year 4\\Thesis\\meetings\\2021_06_28_GL\\new_media\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88383a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>balanced_acc</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>n</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CC</th>\n",
       "      <td>0.986796</td>\n",
       "      <td>0.465209</td>\n",
       "      <td>0.483471</td>\n",
       "      <td>0.237082</td>\n",
       "      <td>0.738271</td>\n",
       "      <td>0.483471</td>\n",
       "      <td>234</td>\n",
       "      <td>38552</td>\n",
       "      <td>269</td>\n",
       "      <td>250</td>\n",
       "      <td>484</td>\n",
       "      <td>39305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KGE</th>\n",
       "      <td>0.979519</td>\n",
       "      <td>0.180915</td>\n",
       "      <td>0.188017</td>\n",
       "      <td>0.092198</td>\n",
       "      <td>0.588702</td>\n",
       "      <td>0.188017</td>\n",
       "      <td>91</td>\n",
       "      <td>38409</td>\n",
       "      <td>412</td>\n",
       "      <td>393</td>\n",
       "      <td>484</td>\n",
       "      <td>39305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NSE</th>\n",
       "      <td>0.978654</td>\n",
       "      <td>0.147117</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.074974</td>\n",
       "      <td>0.570921</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>74</td>\n",
       "      <td>38392</td>\n",
       "      <td>429</td>\n",
       "      <td>410</td>\n",
       "      <td>484</td>\n",
       "      <td>39305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.978654</td>\n",
       "      <td>0.147117</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>0.074974</td>\n",
       "      <td>0.570921</td>\n",
       "      <td>0.152893</td>\n",
       "      <td>74</td>\n",
       "      <td>38392</td>\n",
       "      <td>429</td>\n",
       "      <td>410</td>\n",
       "      <td>484</td>\n",
       "      <td>39305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  precision    recall        f1  balanced_acc  hit_rate   TP  \\\n",
       "model                                                                         \n",
       "CC     0.986796   0.465209  0.483471  0.237082      0.738271  0.483471  234   \n",
       "KGE    0.979519   0.180915  0.188017  0.092198      0.588702  0.188017   91   \n",
       "NSE    0.978654   0.147117  0.152893  0.074974      0.570921  0.152893   74   \n",
       "RMSE   0.978654   0.147117  0.152893  0.074974      0.570921  0.152893   74   \n",
       "\n",
       "          TN   FP   FN    n      N  \n",
       "model                               \n",
       "CC     38552  269  250  484  39305  \n",
       "KGE    38409  412  393  484  39305  \n",
       "NSE    38392  429  410  484  39305  \n",
       "RMSE   38392  429  410  484  39305  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_bench = [file for file in pca_dir.glob(\"*.csv\") if 'range' in file.stem][0]\n",
    "\n",
    "df_bench = pd.read_csv(fn_bench)\n",
    "# df_bench['hit_rate'] = df_bench['hit_ratio']\n",
    "\n",
    "stat_cols = ['accuracy', 'precision', 'recall', 'f1', 'balanced_acc', 'hit_rate',\n",
    "            'TP', 'TN', 'FP', 'FN', 'n', 'N']\n",
    "\n",
    "df_bench.groupby(by='model')[stat_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eafb60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>balanced_acc</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>n</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CC</th>\n",
       "      <td>0.893720</td>\n",
       "      <td>0.467391</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.247126</td>\n",
       "      <td>0.729353</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>43</td>\n",
       "      <td>697</td>\n",
       "      <td>49</td>\n",
       "      <td>39</td>\n",
       "      <td>82</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KGE</th>\n",
       "      <td>0.892512</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.119658</td>\n",
       "      <td>0.571291</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>14</td>\n",
       "      <td>725</td>\n",
       "      <td>21</td>\n",
       "      <td>68</td>\n",
       "      <td>82</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NSE</th>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>0.144068</td>\n",
       "      <td>0.590924</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>17</td>\n",
       "      <td>727</td>\n",
       "      <td>19</td>\n",
       "      <td>65</td>\n",
       "      <td>82</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>0.144068</td>\n",
       "      <td>0.590924</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>17</td>\n",
       "      <td>727</td>\n",
       "      <td>19</td>\n",
       "      <td>65</td>\n",
       "      <td>82</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  precision    recall        f1  balanced_acc  hit_rate  TP  \\\n",
       "model                                                                        \n",
       "CC     0.893720   0.467391  0.524390  0.247126      0.729353  0.524390  43   \n",
       "KGE    0.892512   0.400000  0.170732  0.119658      0.571291  0.170732  14   \n",
       "NSE    0.898551   0.472222  0.207317  0.144068      0.590924  0.207317  17   \n",
       "RMSE   0.898551   0.472222  0.207317  0.144068      0.590924  0.207317  17   \n",
       "\n",
       "        TN  FP  FN   n    N  \n",
       "model                        \n",
       "CC     697  49  39  82  828  \n",
       "KGE    725  21  68  82  828  \n",
       "NSE    727  19  65  82  828  \n",
       "RMSE   727  19  65  82  828  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load TEST benchmark performances\n",
    "\n",
    "test_files = [file for file in pca_dir.glob(\"*.csv\") if  'test' in file.stem]\n",
    "\n",
    "df_bench_1 = pd.read_csv(test_files[0])\n",
    "df_bench_4 = pd.read_csv(test_files[1])\n",
    "\n",
    "df_bench_1.groupby(by='model')[stat_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7476b91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>balanced_acc</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>n</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CC</th>\n",
       "      <td>0.987183</td>\n",
       "      <td>0.467391</td>\n",
       "      <td>0.488636</td>\n",
       "      <td>0.238889</td>\n",
       "      <td>0.740937</td>\n",
       "      <td>0.488636</td>\n",
       "      <td>43</td>\n",
       "      <td>7197</td>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>88</td>\n",
       "      <td>7334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KGE</th>\n",
       "      <td>0.979820</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.585665</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>16</td>\n",
       "      <td>7170</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>88</td>\n",
       "      <td>7334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NSE</th>\n",
       "      <td>0.980365</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.597166</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>18</td>\n",
       "      <td>7172</td>\n",
       "      <td>74</td>\n",
       "      <td>70</td>\n",
       "      <td>88</td>\n",
       "      <td>7334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.980365</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.597166</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>18</td>\n",
       "      <td>7172</td>\n",
       "      <td>74</td>\n",
       "      <td>70</td>\n",
       "      <td>88</td>\n",
       "      <td>7334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy  precision    recall        f1  balanced_acc  hit_rate  TP  \\\n",
       "model                                                                        \n",
       "CC     0.987183   0.467391  0.488636  0.238889      0.740937  0.488636  43   \n",
       "KGE    0.979820   0.173913  0.181818  0.088889      0.585665  0.181818  16   \n",
       "NSE    0.980365   0.195652  0.204545  0.100000      0.597166  0.204545  18   \n",
       "RMSE   0.980365   0.195652  0.204545  0.100000      0.597166  0.204545  18   \n",
       "\n",
       "         TN  FP  FN   n     N  \n",
       "model                          \n",
       "CC     7197  49  45  88  7334  \n",
       "KGE    7170  76  72  88  7334  \n",
       "NSE    7172  74  70  88  7334  \n",
       "RMSE   7172  74  70  88  7334  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bench_4.groupby(by='model')[stat_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cb644d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_k</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_balanced_acc</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_hit_rate</th>\n",
       "      <th>train_n</th>\n",
       "      <th>train_N</th>\n",
       "      <th>train_TP</th>\n",
       "      <th>train_TN</th>\n",
       "      <th>train_FP</th>\n",
       "      <th>train_FN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM-0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.915396</td>\n",
       "      <td>0.605238</td>\n",
       "      <td>0.799154</td>\n",
       "      <td>0.216619</td>\n",
       "      <td>0.170312</td>\n",
       "      <td>0.216619</td>\n",
       "      <td>365.6</td>\n",
       "      <td>3621.6</td>\n",
       "      <td>79.2</td>\n",
       "      <td>3236.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>286.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_k  train_accuracy  train_balanced_acc  train_precision  \\\n",
       "model                                                                 \n",
       "SVM-0      2.0        0.915396            0.605238         0.799154   \n",
       "\n",
       "       train_recall  train_f1  train_hit_rate  train_n  train_N  train_TP  \\\n",
       "model                                                                       \n",
       "SVM-0      0.216619  0.170312        0.216619    365.6   3621.6      79.2   \n",
       "\n",
       "       train_TN  train_FP  train_FN  \n",
       "model                                \n",
       "SVM-0    3236.0      20.0     286.4  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_files = [file for file in pca_dir.glob(\"*.csv\") if 'final' in file.stem]\n",
    "\n",
    "df_final_1 = pd.read_csv(final_files[0])\n",
    "df_final_4 = pd.read_csv(final_files[1])\n",
    "\n",
    "final_cols = df_final_1.columns.values \n",
    "\n",
    "val_cols = [col for col in final_cols if not 'train' in col and not 'test' in col]\n",
    "train_cols = [col for col in final_cols if 'train' in col ]\n",
    "test_cols = [col for col in final_cols if 'test' in col]\n",
    "\n",
    "df_final_1.groupby(by='model')[train_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69037310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_k</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_balanced_acc</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_hit_rate</th>\n",
       "      <th>train_n</th>\n",
       "      <th>train_N</th>\n",
       "      <th>train_TP</th>\n",
       "      <th>train_TN</th>\n",
       "      <th>train_FP</th>\n",
       "      <th>train_FN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM-0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.98998</td>\n",
       "      <td>0.607062</td>\n",
       "      <td>0.787734</td>\n",
       "      <td>0.214825</td>\n",
       "      <td>0.168448</td>\n",
       "      <td>0.214825</td>\n",
       "      <td>387.2</td>\n",
       "      <td>32594.4</td>\n",
       "      <td>83.2</td>\n",
       "      <td>32184.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>304.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_k  train_accuracy  train_balanced_acc  train_precision  \\\n",
       "model                                                                 \n",
       "SVM-0      2.0         0.98998            0.607062         0.787734   \n",
       "\n",
       "       train_recall  train_f1  train_hit_rate  train_n  train_N  train_TP  \\\n",
       "model                                                                       \n",
       "SVM-0      0.214825  0.168448        0.214825    387.2  32594.4      83.2   \n",
       "\n",
       "       train_TN  train_FP  train_FN  \n",
       "model                                \n",
       "SVM-0   32184.6      22.6     304.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_4.groupby(by='model')[train_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c721180",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_single_algorithm_performance(df_performance, grouper='model', \n",
    "                                 stat_cols = ['accuracy', 'precision', 'recall', 'f1', 'balanced_acc'],\n",
    "                                 performance_labels = [], out_dir=None, fn_stem=None, plot_yerr = False):\n",
    "    \n",
    "    sum_performance = df_performance.groupby(by=grouper)[stat_cols].mean()\n",
    "    \n",
    "\n",
    "    var_performance = df_performance.groupby(by=grouper)[stat_cols].std()\n",
    "\n",
    "    \n",
    "    model_types = sum_performance.index.values \n",
    "    \n",
    "    x_plot = np.arange(0, len(stat_cols), 1.)\n",
    "    \n",
    "    for ix_type in model_types:\n",
    "        \n",
    "        if plot_yerr:\n",
    "            y_err = var_performance.loc[ix_type].values\n",
    "        else:\n",
    "            y_err = None\n",
    "        \n",
    "        plt.figure(figsize=(4,3))\n",
    "        plt.bar( x_plot, sum_performance.loc[ix_type].values, \n",
    "               yerr = y_err)\n",
    "        \n",
    "        plt.title(ix_type, size=16)\n",
    "        \n",
    "        if len(performance_labels) != len(x_plot):\n",
    "            plt.xticks(x_plot, stat_cols, rotation=30, size=14)\n",
    "        else:\n",
    "            plt.xticks(x_plot, performance_labels, rotation=30, size=14)\n",
    "        plt.ylim(0,1.1)\n",
    "        plt.yticks(size=14)\n",
    "        plt.grid()\n",
    "        plt.tight_layout() \n",
    "        \n",
    "        if fn_stem is not None:\n",
    "            fn = f'{fn_stem}_{ix_type}.png'\n",
    "#             fn = f'{fn_stem}_{ix_type}.pdf'\n",
    "            if out_dir is not None:\n",
    "                fn = out_dir / fn\n",
    "            plt.savefig(fn)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e26a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pf_labels = ['Accuracy', 'Precision', 'Recall', 'f1-score', 'Balanced Acc.']\n",
    "# # display_single_algorithm_performance(df_bench, performance_labels=pf_labels),\n",
    "# #                                            out_dir = save_dir, fn_stem = 'benchmark_grid')\n",
    "\n",
    "\n",
    "# pca_set, pca_bench = get_pca_files(pca_dir, 'set2', 'grid', fmt = '*.csv')\n",
    "# # df_pca_bench = pd.read_csv(pca_bench[0])\n",
    "\n",
    "# list_files = pca_bench + pca_set \n",
    "# list_models = ['LR-2', 'RF-2', 'SVM-2', 'k-nn-2']\n",
    "# target_names = [ model_str.split('-')[0] for model_str in list_models ]\n",
    "\n",
    "# for ix_cat, fn in enumerate(list_files):\n",
    "    \n",
    "#     out_fn = f'set2_grid_{ fn.stem.split(\"_\")[3] }'\n",
    "    \n",
    "#     df = pd.read_csv(fn)    \n",
    "#     df = df[ df['model'].isin(list_models) ].copy()\n",
    "    \n",
    "#     for i, model_type in enumerate(list_models):\n",
    "#         df.loc[ df['model'] == model_type, 'rename_model' ] = target_names[i] \n",
    "    \n",
    "#     sns.barplot(x=\"model\", y=\"accuracy\", data=df)\n",
    "    \n",
    "    \n",
    "#     display_single_algorithm_performance(df, grouper='rename_model',\n",
    "#                                         performance_labels = pf_labels,\n",
    "#                                         out_dir = save_dir, fn_stem = out_fn)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666edb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c8bc09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95179143",
   "metadata": {},
   "outputs": [],
   "source": [
    "## base \n",
    "\n",
    "def display_performance(benchmark_0, benchmark_1, list_performance_fn, grouper = 'model',\n",
    "                        stat_cols=['accuracy', 'precision', 'recall', 'f1', 'balanced_acc'], performance_labels = [],\n",
    "                       out_dir = None, fn_stem = None):\n",
    "    \n",
    "    ## benchmark\n",
    "    sum_bench0 = benchmark_0.groupby(by=grouper)[stat_cols].mean()\n",
    "    bench0_algs = sum_bench0.index.values\n",
    "\n",
    "    ## benkchmark performance model\n",
    "    sum_bench1 = benchmark_1.groupby(by=grouper)[stat_cols].mean() \n",
    "    var_bench_min = benchmark_1.groupby(by=grouper)[stat_cols].min()\n",
    "    var_bench_max = benchmark_1.groupby(by=grouper)[stat_cols].max()\n",
    "    eval_algs = sum_bench1.index.values \n",
    "  \n",
    "    ## load list of df_performance \n",
    "    list_performance_df = []\n",
    "    list_var_min = [] \n",
    "    list_var_max = []\n",
    "    \n",
    "    for fn in list_performance_fn:\n",
    "\n",
    "        _df = pd.read_csv(fn)\n",
    "        \n",
    "        sum_df = _df.groupby(by=grouper)[stat_cols].mean()\n",
    "        list_performance_df.append(sum_df)\n",
    "\n",
    "        \n",
    "        var_min = _df.groupby(by=grouper)[stat_cols].min()\n",
    "        var_max = _df.groupby(by=grouper)[stat_cols].max()\n",
    "        list_var_min.append(var_min)\n",
    "        list_var_max.append(var_max)\n",
    "\n",
    "\n",
    "\n",
    "    for col in stat_cols:\n",
    "\n",
    "        fig = plt.figure(figsize=(14,4))\n",
    "        x_plot = 0.\n",
    "\n",
    "        x_tick_loc = []\n",
    "        x_tick_label = []\n",
    "\n",
    "        plt.title(col, size=16) # .capitalize()\n",
    "        \n",
    "        if col in ['TP', 'FP', 'TN', 'FN']:\n",
    "            bench_factor = 0.2 \n",
    "        else:\n",
    "            bench_factor = 1.\n",
    "\n",
    "        for alg in bench0_algs:\n",
    "            plt.bar(x_plot, sum_bench0.loc[alg,col]*bench_factor, width=3, color='grey', label='Benchmark')\n",
    "\n",
    "            x_tick_loc.append(x_plot)\n",
    "            x_tick_label.append(alg)\n",
    "\n",
    "            x_plot += 3.5\n",
    "\n",
    "        x_plot += 4\n",
    "\n",
    "        select_cmap = cm.cubehelix(np.linspace(0,0.8, len(list_performance_df)))\n",
    "        \n",
    "        var_labels = ['60% var explained', '70% var explained', '80% var explained',\n",
    "                     '90% var explained', '95% var explained', '99% var explained'] \n",
    "\n",
    "        for alg in eval_algs:\n",
    "                        \n",
    "            if '2' in alg:\n",
    "                \n",
    "                alg_name = alg.split('-')[0]\n",
    "                \n",
    "                if 'k-nn' in alg:\n",
    "                    alg_name = 'k-nn'\n",
    "                \n",
    "                \n",
    "                err_min = sum_bench1.loc[alg,col] - var_bench_min.loc[alg,col]  \n",
    "                err_max = var_bench_max.loc[alg,col] -  sum_bench1.loc[alg,col] \n",
    "                y_err = np.array([ [err_min], [err_max]])\n",
    "\n",
    "                plt.bar(x_plot, sum_bench1.loc[alg,col], width=3, color='dimgrey',\n",
    "                       yerr = y_err, label='No PCA')\n",
    "\n",
    "    #             if len(performance_labels) > 0:\n",
    "    #                 plt.text(x_plot-0.1, 0.1, performance_labels[0], rotation = 90, color = 'black', size=8)\n",
    "\n",
    "                x_tick_loc.append( (x_plot+ 1.75*len(list_performance_df)) )\n",
    "                x_tick_label.append(alg_name)\n",
    "                x_plot += 3.5 \n",
    "\n",
    "                for i, df_alg in enumerate(list_performance_df):\n",
    "                    \n",
    "                    err_min = df_alg.loc[alg,col] - list_var_min[i].loc[alg,col]\n",
    "                    err_max = list_var_max[i].loc[alg,col] - df_alg.loc[alg,col]\n",
    "                    y_err = np.array([[err_min], [err_max]])\n",
    "                    \n",
    "                    plt.bar(x_plot, df_alg.loc[alg,col], width = 3, color=select_cmap[i], # color='cadetblue',\n",
    "                            yerr= y_err, \n",
    "                            label = var_labels[i])\n",
    "                        \n",
    "#                     if len(performance_labels) > 0:\n",
    "#                         plt.text(x_plot-1, 0.1, performance_labels[i], color = 'black', size=8, rotation=90)\n",
    "\n",
    "                    x_plot += 3.5\n",
    "\n",
    "                x_plot += 4 \n",
    "        \n",
    "        if col in ['TP', 'FP', 'TN', 'FN']:\n",
    "            plt.ylim(0,100)\n",
    "            plt.yticks(np.arange(0,101, 10), np.arange(0,101, 10))\n",
    "        else:\n",
    "            plt.ylim(0,1.05)\n",
    "            plt.yticks(np.arange(0, 1.05, 0.1), ['{:.1f}'.format(v) for v in np.arange(0, 1.05, 0.1)])\n",
    "        \n",
    "        plt.xticks(x_tick_loc, x_tick_label, size = 14, rotation = 50)\n",
    "        plt.grid()\n",
    "        \n",
    "        \n",
    "#         handles, labels = plt.gca().get_legend_handles_labels() \n",
    "#         by_label = dict(zip(labels, handles))\n",
    "#         plt.legend(by_label.values(), by_label.keys(), bbox_to_anchor=(1,0.95), fontsize=14)\n",
    "    \n",
    "        plt.xlim(-2, x_plot-1)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if out_dir != None:\n",
    "            if fn_stem == None:\n",
    "                fn = out_dir / 'plot_{}.png'.format(col)\n",
    "            else:\n",
    "                fn = out_dir / 'plot_{}_{}.png'.format(fn_stem, col)\n",
    "            plt.savefig(fn)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99526244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bdbfed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### set 1 - single pixel \n",
    "labels = ['60%', '70%', '80%', '90%', '95%', '99%' ]\n",
    "display_cols = [\n",
    "#                 'accuracy', \n",
    "                'precision', 'recall', 'f1', 'balanced_acc', \n",
    "#                 'hit_rate',\n",
    "                'TP', 'FP', #'TN', 'FN', \n",
    "#                 'n', 'N']\n",
    "                ]\n",
    "\n",
    "fig_dir = test_dir \n",
    "\n",
    "select_set = 'set1_4'\n",
    "select_format = 'pf_single'\n",
    "\n",
    "\n",
    "\n",
    "pca_set, pca_bench = get_pca_files(pca_dir, select_set, select_format, fmt = '*.csv')\n",
    "\n",
    "df_pca_bench = pd.read_csv(pca_bench[0])\n",
    "\n",
    "display_performance( df_bench, df_pca_bench, pca_set, performance_labels = labels,\n",
    "                     stat_cols = display_cols, \n",
    "#                      out_dir = save_dir, fn_stem= f'{select_set}_{select_format}'\n",
    "                   )\n",
    "\n",
    "\n",
    "# df_pca_bench.groupby(by='model')[stat_cols].mean().loc[['RF-2', 'SVM-2', 'k-nn-2', 'LR-2' ]]\n",
    "\n",
    "# ix=0\n",
    "# print(pca_set[ix].stem)\n",
    "# df = pd.read_csv(pca_set[ix])\n",
    "# df.groupby(by='model')[stat_cols].mean().loc[['RF-2', 'SVM-2', 'k-nn-2', 'LR-2' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f7bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dir2 =  test_dir / \"PCA_analysis_3\" \n",
    "\n",
    "select_set = 'set1_0'\n",
    "select_format = 'pf_single'\n",
    "\n",
    "pca_set, pca_bench = get_pca_files(pca_dir2, select_set, select_format, fmt = '*.csv')\n",
    "\n",
    "df_pca_bench = pd.read_csv(pca_bench[0])\n",
    "\n",
    "# display_performance( df_bench, df_pca_bench, pca_set, performance_labels = labels,\n",
    "#                      stat_cols = display_cols, \n",
    "#                      out_dir = save_dir, fn_stem= f'{select_set}_{select_format}'\n",
    "#                    )\n",
    "# \n",
    "# df_pca_bench.groupby(by='model')[stat_cols].mean().loc[['RF-2', 'SVM-2', 'k-nn-2', 'LR-2' ]]\n",
    "\n",
    "ix=0\n",
    "print(pca_set[ix])\n",
    "df = pd.read_csv(pca_set[ix])\n",
    "df.groupby(by='model')[stat_cols].mean().loc[['RF-2', 'SVM-2', 'k-nn-2', 'LR-2' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pca_bench.groupby(by='model')[stat_cols].mean().loc[['RF-2', 'SVM-2', 'k-nn-2', 'LR-2' ]]\n",
    "\n",
    "# ix=0\n",
    "# print(pca_set[ix].stem)\n",
    "# df = pd.read_csv(pca_set[ix])\n",
    "# df.groupby(by='model')[stat_cols].mean().loc[['RF-2', 'SVM-2', 'k-nn-2', 'LR-2' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea84d0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1a4a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367510e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544c3188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3835d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pareto(benchmark_0, benchmark_1, list_performance_fn, grouper = 'model',\n",
    "                performance_labels = [],\n",
    "                out_dir = None, fn_stem = None):\n",
    "    \n",
    "    pareto_cols = ['precision', 'recall']\n",
    "    \n",
    "    ## benchmark\n",
    "    sum_bench0 = benchmark_0.groupby(by=grouper)[pareto_cols].mean()\n",
    "    bench0_algs = sum_bench0.index.values\n",
    "\n",
    "    ## benkchmark performance model\n",
    "    sum_bench1 = benchmark_1.groupby(by=grouper)[pareto_cols].mean() \n",
    "    eval_algs = [ alg for alg in sum_bench1.index.values if '2' in alg]\n",
    "  \n",
    "    ## load list of df_performance \n",
    "    list_performance_df = []\n",
    "    for fn in list_performance_fn:\n",
    "\n",
    "            _df = pd.read_csv(fn)\n",
    "\n",
    "            sum_df = _df.groupby(by=grouper)[pareto_cols].mean()\n",
    "            list_performance_df.append(sum_df)\n",
    "\n",
    "    \n",
    "    select_cmap = cm.gnuplot(np.linspace(0., 0.9, len(eval_algs) )) \n",
    "\n",
    "#     select_cmap = []\n",
    "    \n",
    "    show_markers = [\"v\", \"^\", \"*\", \"s\", \"d\", \"p\", \".\", 'x']\n",
    "    \n",
    "    fig = plt.figure(figsize=(6,5)) \n",
    "    \n",
    "    # plot bench \n",
    "    plt.plot( sum_bench0[pareto_cols[0]].values, sum_bench0[pareto_cols[1]].values,\n",
    "            linestyle='none', marker = 'o', markersize=6, \n",
    "            color = 'royalblue',\n",
    "             label='benchmark'\n",
    "            )  \n",
    "\n",
    "    for i, alg in enumerate(eval_algs):  \n",
    "        \n",
    "        if '2' in alg:\n",
    "        \n",
    "            plt.plot(sum_bench1.loc[alg, pareto_cols[0]], sum_bench1.loc[alg, pareto_cols[1]],\n",
    "                linestyle='none', \n",
    "                marker = 'x', \n",
    "                markersize=6, \n",
    "                color = select_cmap[i], \n",
    "                label= f'{alg} - no PCA'\n",
    "                )       \n",
    "\n",
    "            for j, df in enumerate(list_performance_df):\n",
    "                \n",
    "                if len(performance_labels) > 0:\n",
    "                    set_label = f'{alg} - {performance_labels[j]}'\n",
    "                else:\n",
    "                    if j == 0:\n",
    "                            set_label = alg\n",
    "                    else:\n",
    "                        set_label = None\n",
    "                    \n",
    "                plt.plot( \n",
    "                    df.loc[alg, pareto_cols[0]], df.loc[alg, pareto_cols[1]],\n",
    "                    linestyle='none', marker=show_markers[j], markersize=6,\n",
    "                    color = select_cmap[i],\n",
    "                    label= set_label \n",
    "                )\n",
    "        \n",
    "    \n",
    "    plt.xlabel(pareto_cols[0].capitalize(), size=16)\n",
    "    plt.ylabel(pareto_cols[1].capitalize(), size=16)\n",
    "    plt.xticks(size=14)\n",
    "    plt.yticks(size=14)\n",
    "    plt.grid()\n",
    "    lgd = plt.legend(bbox_to_anchor=(1.1,1), ncol=2, fontsize=16 )\n",
    "    \n",
    "    plt.xlim(-0.05, 1.05)\n",
    "    plt.ylim(-0.05, 1.05)\n",
    "#     plt.tight_layout()\n",
    "\n",
    "    if out_dir != None:\n",
    "        if fn_stem == None:\n",
    "            fn = out_dir / 'plot_pareto.png'.format(col)\n",
    "        else:\n",
    "            fn = out_dir / 'plot_pareto_{}.png'.format(fn_stem)\n",
    "\n",
    "        plt.savefig(fn, bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ab873",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "select_set = 'set1_4'\n",
    "select_format = 'pf_single'\n",
    "\n",
    "save_file = f'{select_set}_{select_format}'\n",
    "\n",
    "pca_set, pca_bench = get_pca_files(pca_dir, select_set, select_format, fmt = '*.csv')\n",
    "\n",
    "df_pca_bench = pd.read_csv(pca_bench[0])\n",
    "\n",
    "\n",
    "plot_pareto(df_bench, df_pca_bench, pca_set,\n",
    "            performance_labels = labels,\n",
    "#             out_dir = save_dir, fn_stem = save_file\n",
    "           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4e349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pca_bench.groupby(by='model').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a809f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bench.groupby(by='model').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd413a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca30c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484cd517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae526e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dfd4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834647f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2055922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39335360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c24f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bb9651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee89343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e1340e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a6cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load classification results - analyse p0 and p1 for TP and FP\n",
    "\n",
    "class_files = [file for file in pca_dir.glob('*.csv') if 'cl' in file.stem]\n",
    "set1_class = [file for file in class_files if 'set1_0' in file.stem]\n",
    "set2_class = [file for file in class_files if 'set2' in file.stem]\n",
    "\n",
    "map_files = [file for file in pca_dir.glob('*.nc') if '_4_' in file.stem and '60PCA' in file.stem] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdafb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd2cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(map_files[0])\n",
    "\n",
    "gauge_ids = np.unique([int(gid.split('_')[0]) for gid in ds.val.values])\n",
    "\n",
    "layer_types = [ '_'.join( gid.split('_')[1:] ) for gid in ds.val.values if 'SVM-2' in gid ]\n",
    "\n",
    "unique_layers = [x for i, x in enumerate(layer_types) if i== layer_types.index(x)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacee296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(df, range_col, target_col, model, title, save_dir = None,\n",
    "                  label_1 = 'TP', label_2 = 'FP', id_col = 'tag'):\n",
    "    \n",
    "    ## TP \n",
    "    ## if prediction in one of range_col \n",
    "    if 'TP' in label_1:\n",
    "        \n",
    "        ix_TP = []\n",
    "        \n",
    "        for ix in df[id_col].unique(): \n",
    "            nTP = df[ (df[id_col] ==  ix) & (df[range_col] == 1) ]\n",
    "            \n",
    "            # predict\n",
    "#             if df[ (df[id_col] ==ix) & (df[hat_col]==1.) ].index in nTP.index.values:\n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "        ## TP \n",
    "        plot_1 = df[ (df[range_col] ==1) & (df[hat_col]==1) ]        \n",
    "    \n",
    "    if 'TP' in label_2:\n",
    "        ## TP if prediction in one of range_col \n",
    "        plot_2 = df[ (df[range_col] ==1) & (df[hat_col]==1) ] \n",
    "    \n",
    "    ## FP \n",
    "    ## if 0 in range col, but 1 for hat_col \n",
    "    if 'FP' in label_1:\n",
    "        plot_1 = df[ (df[range_col] ==0) & (df[hat_col]==1) ] \n",
    "    \n",
    "    if 'FP' in label_2:\n",
    "        plot_2 = df[ (df[range_col] ==0) & (df[hat_col]==1) ] \n",
    "    \n",
    "    ## TN \n",
    "    ## if 0 in range col and 0 for hat_col \n",
    "    if 'TN' in label_1:\n",
    "        plot_1 = df[ (df[range_col] ==0) & (df[hat_col]==0) ] \n",
    "    \n",
    "    if 'TN' in label_2:\n",
    "        plot_2 = df[ (df[range_col] ==0) & (df[hat_col]==0) ] \n",
    "    \n",
    "    ## FN \n",
    "    ## if 0 in range col and 0 for hat_col \n",
    "    if 'FN' in label_1:\n",
    "        plot_1 = df[ (df[range_col] ==1) & (df[hat_col]==0) ] \n",
    "    \n",
    "    if 'FN' in label_2:\n",
    "        plot_2 = df[ (df[range_col] ==1) & (df[hat_col]==0) ] \n",
    "\n",
    "        \n",
    "    ## plot\n",
    "    fig, (ax1, ax2) = plt.subplots(2)\n",
    "    ax1.hist(plot_1[p1_col], color = 'royalblue', label = label_1, bins = bin_edges )\n",
    "#     ax2 = ax1.twinx()\n",
    "    ax2.hist(plot_2[p1_col], color = 'crimson', label = label_2, bins = bin_edges )\n",
    "    \n",
    "    ax1.tick_params(axis='y', labelcolor='b')\n",
    "    ax2.tick_params(axis='y', labelcolor='r')\n",
    "    \n",
    "    ax1.set_xlim(0,1.05)\n",
    "    ax1.set_ylim(0,8)\n",
    "    ax2.set_ylim(0,8)\n",
    "    \n",
    "    ax1.set_xlabel('Class 1 probability')\n",
    "    ax1.set_ylabel('n {}'.format(label_1), color='b')\n",
    "    ax2.set_ylabel('n {}'.format(label_2), color='r')\n",
    "    \n",
    "    \n",
    "#     fig.legend()\n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if save_dir != None:\n",
    "        fn = save_dir / 'distr_{}_{}_{}.png'.format(title, label_1, label_2)\n",
    "        print('Save: ', fn.stem)\n",
    "        plt.savefig(fn)\n",
    "        return fn \n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fef2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SET -1 - TN and FP \n",
    "range_col = 'range_target'\n",
    "target_col = 'target'\n",
    "\n",
    "model = 'SVM-2'\n",
    "p0_col = '{}_p0'.format(model)\n",
    "p1_col = '{}_p1'.format(model)\n",
    "hat_col = '{}_target'.format(model)\n",
    "\n",
    "bin_edges = np.arange(0,1.01, 0.02)\n",
    "\n",
    "label_files = ['set_1_60PCA_{}'.format(model),\n",
    "              'set_1_70PCA_{}'.format(model),\n",
    "              'set_1_80PCA_{}'.format(model),\n",
    "              'set_1_90PCA_{}'.format(model),\n",
    "              'set_1_95PCA_{}'.format(model),\n",
    "              'set_1_99PCA_{}'.format(model),\n",
    "              'set_1_noPCA_{}'.format(model)]\n",
    "\n",
    "\n",
    "for n, fn in enumerate(set1_class):\n",
    "    \n",
    "    df = pd.read_csv(fn, index_col=0)\n",
    "    print(fn)\n",
    "    \n",
    "    plot_confusion(df, range_col, target_col, model, label_files[n], \n",
    "#                    save_dir = save_dir,\n",
    "                  label_1 = 'FN', label_2 = 'FP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5154297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df28f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_files = ['set_2_60PCA',\n",
    "              'set_2_70PCA',\n",
    "              'set_2_80PCA',\n",
    "              'set_2_90PCA',\n",
    "              'set_2_95PCA',\n",
    "              'set_2_99PCA',\n",
    "              'set_2_noPCA',]\n",
    "\n",
    "\n",
    "for n, fn in enumerate(set2_class):\n",
    "    \n",
    "    df = pd.read_csv(fn, index_col=0)\n",
    "    \n",
    "    plot_confusion(df, range_col, target_col, model, label_files[n], save_dir = None,\n",
    "                  label_1 = 'TP', label_2 = 'FP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3416e318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
